<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="fr">
  <siteinfo>
    <sitename>Wikipédia</sitename>
    <dbname>frwiki</dbname>
    <base>https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal</base>
    <generator>MediaWiki 1.30.0-wmf.16</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Média</namespace>
      <namespace key="-1" case="first-letter">Spécial</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Discussion</namespace>
      <namespace key="2" case="first-letter">Utilisateur</namespace>
      <namespace key="3" case="first-letter">Discussion utilisateur</namespace>
      <namespace key="4" case="first-letter">Wikipédia</namespace>
      <namespace key="5" case="first-letter">Discussion Wikipédia</namespace>
      <namespace key="6" case="first-letter">Fichier</namespace>
      <namespace key="7" case="first-letter">Discussion fichier</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">Discussion MediaWiki</namespace>
      <namespace key="10" case="first-letter">Modèle</namespace>
      <namespace key="11" case="first-letter">Discussion modèle</namespace>
      <namespace key="12" case="first-letter">Aide</namespace>
      <namespace key="13" case="first-letter">Discussion aide</namespace>
      <namespace key="14" case="first-letter">Catégorie</namespace>
      <namespace key="15" case="first-letter">Discussion catégorie</namespace>
      <namespace key="100" case="first-letter">Portail</namespace>
      <namespace key="101" case="first-letter">Discussion Portail</namespace>
      <namespace key="102" case="first-letter">Projet</namespace>
      <namespace key="103" case="first-letter">Discussion Projet</namespace>
      <namespace key="104" case="first-letter">Référence</namespace>
      <namespace key="105" case="first-letter">Discussion Référence</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Discussion module</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Discussion gadget</namespace>
      <namespace key="2302" case="case-sensitive">Définition de gadget</namespace>
      <namespace key="2303" case="case-sensitive">Discussion définition de gadget</namespace>
      <namespace key="2600" case="first-letter">Sujet</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Antoine Meillet</title>
    <ns>0</ns>
    <id>3</id>
    <revision>
      <id>132619287</id>
      <parentid>132619275</parentid>
      <timestamp>2016-12-12T12:49:09Z</timestamp>
      <contributor>
        <username>Hercule</username>
        <id>271994</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">
bob<sup>bib</sup>bab
</text>
      <sha1>4gdegly44pdfqd8qjreat0jca3dcow6</sha1>
    </revision>
  </page>
  <page>
    <title>Algèbre linéaire</title>
    <ns>0</ns>
    <id>7</id>
    <revision>
      <id>135686288</id>
      <parentid>135686234</parentid>
      <timestamp>2017-03-23T08:59:54Z</timestamp>
      <contributor>
        <username>Fschwarzentruber</username>
        <id>2401391</id>
      </contributor>
      <comment>plus simple</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{Voir homonymes|Algèbre (homonymie)}}
[[Fichier:Linear subspaces with shading.svg|vignette|'''R&lt;sup&gt;3&lt;/sup&gt;''' est un espace vectoriel de dimension 3. Droites et plans qui passent par l'origine sont des sous-espaces vectoriels.]]
L’'''algèbre linéaire''' est la branche des [[mathématiques]] qui s'intéresse aux [[Espace vectoriel|espaces vectoriels]] et aux [[Application linéaire|transformations linéaires]], formalisation générale des théories des [[Système d'équations linéaires|systèmes d'équations linéaires]].

== Histoire ==
L'histoire de l'algèbre linéaire commence avec [[Al-Khawarizmi]] qui a traduit des textes de mathématiques indiens, réinterprété les travaux de l'école grecque et qui est la source du développement conscient de l'algèbre qui s'étendra pendant des siècles après lui&lt;ref&gt;[[Roshdi Rashed]], ''D'Al Khwarizmi à Descartes, Étude sur l'histoire des mathématiques classiques'', Hermann, 2011&lt;/ref&gt;. Elle a été reprise par [[René Descartes]] qui pose des problèmes de [[géométrie]], comme la détermination de l'intersection de deux [[Droite (mathématiques)|droites]], en termes d'[[équation linéaire]], établissant dès lors un pont entre deux branches mathématiques jusqu'alors séparées : l'[[algèbre]] et la géométrie. S'il ne définit pas la notion de base de l'algèbre linéaire qu'est celle d'espace vectoriel, il l'utilise déjà avec succès, et cette utilisation naturelle des aspects linéaires des équations manipulées demeurera utilisée de manière ad hoc, fondée essentiellement sur les idées géométriques sous-jacentes. Après cette découverte, les progrès en algèbre linéaire vont se limiter à des études ponctuelles comme la définition et l'analyse des premières propriétés des [[déterminant (mathématiques)|déterminants]] par [[Jean le Rond D'Alembert|Jean d'Alembert]]. 

Ce n'est qu'au {{XIXe siècle}} que l'algèbre linéaire devient une branche des mathématiques à part entière. [[Carl Friedrich Gauss]] trouve [[Élimination de Gauss-Jordan|une méthode générique]] pour la résolution des systèmes d'équations linéaires et [[Camille Jordan (mathématicien)|Camille Jordan]] résout définitivement le problème de la [[réduction d'endomorphisme]]. En 1843, [[William Rowan Hamilton]] (inventeur du terme ''vector'') découvre les [[quaternion]]s ([[Algèbre centrale simple|extension]] de degré 4 du [[corps commutatif|corps]] des [[nombre réel|nombres réels]]). En 1844, [[Hermann Günther Grassmann|Hermann Grassmann]] publie son traité ''Die lineale Ausdehnungslehre'', ''La théorie de l'extension linéaire'', qui est la première tentative de formalisation générale de la notion d'espace vectoriel. Si son œuvre reste grandement inaperçue, elle contient l'essentiel des idées modernes de l'algèbre linéaire, et cette étape fondamentale dans le développement de l'algèbre linéaire est reconnue comme telle tant par Hamilton que par [[Giuseppe Peano]], qui axiomatise entièrement la théorie en 1888. Les espaces vectoriels deviennent alors une structure générale omniprésente dans presque tous les domaines mathématiques, notamment en [[analyse (mathématiques)|analyse]] ([[espace fonctionnel|espaces de fonctions]]).

== Intérêt ==
Sous leur forme la plus simple, les applications linéaires dans les [[Espace vectoriel|espaces vectoriels]] représentent intuitivement les déplacements dans les espaces géométriques élémentaires comme la [[Droite (mathématiques)|droite]], le [[Plan (mathématiques)|plan]] ou notre [[Espace (notion)#Physique|espace]] physique. Les bases de cette théorie remplacent maintenant la représentation construite par [[Euclide]] au {{IIIe siècle av. J.-C.}}. La construction moderne permet de généraliser la notion d'espace à des dimensions quelconques.

L'algèbre linéaire permet de résoudre tout un ensemble d'équations dites linéaires utilisées non seulement en mathématiques ou en [[Mécanique (science)|mécanique]], mais dans de nombreuses autres branches comme les [[sciences naturelles]] ou les [[sciences sociales]].

Les espaces vectoriels forment aussi un outil fondamental pour les [[sciences de l'ingénieur]] et servent de base à de nombreux domaines dans la [[recherche opérationnelle]].

Enfin, c'est un outil utilisé en mathématiques dans des domaines aussi divers que la [[théorie des groupes]], [[Théorie des anneaux|des anneaux]] ou [[Théorie des corps|des corps]], l'[[Analyse fonctionnelle (mathématiques)|analyse fonctionnelle]], la [[géométrie différentielle]] ou la [[théorie des nombres]].

== Présentation élémentaire ==
L'algèbre linéaire commence par l'étude de [[vecteur]]s dans les espaces cartésiens de dimension 2 et 3. Un vecteur, ici, est une classe d'équivalence de bipoints qui unifie les segments de droite caractérisés à la fois par leur longueur (ou ''norme''), leur direction et leur sens : deux bipoints représentent un même vecteur si le quadrilatère formé sur les quatre points est un parallélogramme. Les vecteurs peuvent alors être utilisés pour représenter certaines entités physiques comme des déplacements, additionnés entre eux ou encore multipliés par des scalaires (''nombres''), formant ainsi le premier exemple concret d'espace vectoriel.

L'algèbre linéaire moderne s'intéresse beaucoup aux espaces de [[Dimension d'un espace vectoriel|dimension arbitraire, éventuellement infinie]]. La plupart des résultats obtenus en dimension 2 ou 3 peuvent être étendus aux dimensions finies supérieures. Les vecteurs étant des listes ordonnées à n composantes, on peut manipuler ces données efficacement dans cet environnement. Par exemple en [[Sciences économiques|économie]], on peut créer et utiliser des vecteurs à huit dimensions pour représenter le [[produit national brut]] de huit pays.

== Quelques théorèmes ==
* [[Théorème de la base incomplète]]&lt;ref&gt;Dans le cas où ''G ''est infinie, ce théorème utilise l'[[axiome du choix]].&lt;/ref&gt; : soient ''E ''un espace vectoriel, ''G ''une [[famille génératrice]] de ''E ''et ''L ''une [[famille libre]] de vecteurs de ''E''. Alors il existe au moins une [[base (algèbre linéaire)|base]] de ''E ''formée en prenant la réunion de ''L ''et d'une partie de ''G''.
* En particulier, tout espace vectoriel possède au moins une base.
* Toutes les bases d'un même espace vectoriel ont le même [[Cardinalité (mathématiques)|cardinal]].
* Tout espace vectoriel A possède un [[espace dual]] A* ; si A est [[Espace vectoriel de dimension finie|de dimension finie]], A* est de même dimension.
* [[Formule de Grassmann]] : Soient &lt;math&gt;F&lt;/math&gt; et &lt;math&gt;G&lt;/math&gt; deux [[Sous-espace vectoriel|sous-espaces vectoriels]] d'un même espace vectoriel. On a alors :&lt;!--MERCI DE NE PAS MODIFIER LES SIGNES DE CETTE FORMULE : en cas de doute, consulter l'article &quot;Formule de Grassmann&quot;--&gt;&lt;center&gt;&lt;math&gt;\dim(F)+\dim(G)=\dim(F+G)+\dim(F\cap G).&lt;/math&gt;&lt;/center&gt;

D'autres théorèmes concernent les conditions d'inversion de [[Matrice (mathématiques)|matrices]] de divers types :
* [[matrice diagonale]] ;
&lt;!--* bande ?--&gt;
* [[matrice triangulaire]] ;
* [[matrice à diagonale dominante]] {{refsou|date=mars 2013|(très utilisées en analyse numérique)}}.

Un théorème intéressant à l'époque des mémoires d'ordinateurs de petite taille était qu'on pouvait travailler séparément sur des sous-ensembles (« blocs ») d'une matrice en les combinant ensuite par les mêmes règles qu'on utilise pour combiner des scalaires dans les matrices (''cf''. l’article [[Matrice par bloc]]). Avec les mémoires actuelles de plusieurs [[gigaoctet]]s, cette question a perdu un peu de son intérêt pratique, mais reste très prisée en [[théorie des nombres]], pour la [[décomposition en produit de facteurs premiers]] avec le [[crible général de corps de nombres (GNFS)]] (''[[Algorithme de Lanczos|méthode Lanczos]] [[Matrice par bloc|par blocs]]'').

== Utilisations ==
Les espaces vectoriels forment le support et le fondement de l'algèbre linéaire. Ils sont aussi présents dans de nombreux domaines distincts. S'il n'est pas possible d'indiquer ici tous les cas d'utilisation, on peut tout de même citer pour les principales structures objet de théories, des exemples significatifs. Leurs rôles dans de vastes théories ne traitant pas d'une structure particulière, comme celles des [[théorie algébrique des nombres|nombres algébriques]] ou  de [[Théorie de Galois|Galois]] peuvent aussi être évoqués.

Les espaces vectoriels utilisés sont d'une grande diversité. On y trouve les classiques espaces vectoriels de dimension 2 ou 3 sur les [[nombre réel|nombres réels]], cependant la dimension peut être quelconque, même infinie. Les nombres complexes sont aussi très utilisés, ainsi que les [[nombre rationnel|rationnels]]. Il n'est pas rare qu'une partie des nombres réels ou complexes soit considéré comme un espace vectoriel rationnel. Le corps de base peut aussi contenir un nombre fini d'éléments, définissant parfois un [[espace vectoriel fini]].

Les propriétés géométriques de la structure permettent la démonstration de nombreux théorèmes. Elles ne se limitent pas aux cas où l'espace est réel, même dans le cas de corps plus insolites comme les [[corps fini]]s ou les [[extension finie|extensions finies]] des rationnels, les propriétés géométriques s'avèrent parfois essentielles.

=== Groupe fini ===
{{Article détaillé|Représentations d'un groupe fini}}
[[Fichier:Rotations du cube.jpg|thumb|[[Représentations du groupe symétrique|Représentation du groupe symétrique d'indice 4]] comme groupe des rotations du cube dans un espace vectoriel de dimension 3.]]

La [[Groupe fini#Classification des groupes finis|classification des groupes finis]] est une vaste question, encore objet de recherche. Si le groupe contient un petit nombre d'éléments, les [[théorèmes de Sylow]] peuvent suffire pour en déterminer la structure. Une méthode beaucoup plus puissante est nécessaire dans le cas général.

[[Ferdinand Georg Frobenius|Georg Frobenius]], à la suite de travaux de [[Richard Dedekind]], développe une nouvelle théorie&lt;ref&gt;{{en}} [[Charles W. Curtis|C. W. Curtis]], « Representation theory of finite groups, from Frobenius to Brauer », dans ''[[The Mathematical Intelligencer|Math. Intelligencer]]'', 1992, p. 48-57&lt;/ref&gt; en [[1896 en science|1896]]. Elle se fonde sur l'idée que l'ensemble des [[symétrie]]s d'un espace vectoriel possède une structure de groupe. Il est toujours possible de ''représenter'' un groupe fini par des symétries bien choisies sur un espace vectoriel de dimension suffisante. Un groupe est ainsi incarné par des transformations géométriques simples. Une telle incarnation prend le nom de ''représentation d'un groupe''.

Les espaces vectoriels choisis sont de dimension finie, en général sur le corps des complexes&lt;ref&gt;Les 11 premiers chapitres de {{Serre2}} ne concernent que les espaces vectoriels complexes.&lt;/ref&gt;, cependant pour disposer de bonnes propriétés arithmétiques le corps peut être celui des [[nombre rationnel|rationnels]]&lt;ref&gt;{{en}} [[Walter Feit]], ''Characters of finite groups'', Benjamin, 1967&lt;/ref&gt; ou encore utiliser des [[entier algébrique|entiers algébriques]] comme pour la démonstration du [[Théorème de Burnside (groupe résoluble)|théorème de Burnside sur les groupes résolubles]]&lt;ref&gt;{{en}} [[William Burnside]], ''Theory of Groups of Finite Order'', Dover, 2004&lt;/ref&gt;. [[Richard Brauer]] étudie un cas très abstrait, celui des représentations sur un espace vectoriel construit à l'aide d'un [[corps fini]]&lt;ref&gt;{{de}} [[Richard Brauer]], « Über die Darstellung von Gruppen in Galoisschen Feldern », dans ''[[Hermann (éditions)#1876-1956|Act. Sci. Ind.]]'', vol. 195, 1935&lt;/ref&gt;. 

Un exemple relativement simple d'utilisation de cette théorie est donné par Burnside, avec [[Théorème de Burnside (problème de 1902)|son théorème]] sur les [[sous-groupe]]s d'[[Exposant d'un groupe|exposant]] fini du [[groupe (mathématiques)|groupe]] [[Groupe général linéaire|linéaire]] GL(''n'', [[nombre complexe|ℂ]]).

=== Anneau ===
{{Article détaillé|Théorie des anneaux}}
[[Fichier:Noether.jpg|thumb|left|[[Emmy Noether]] utilise la notion d'espace vectoriel pour étudier les [[Anneau noethérien|anneaux]] portant maintenant son nom.]]
Un exemple célèbre d'anneau disposant aussi d'une structure d'espace vectoriel est celui des [[polynôme formel|polynômes]] à coefficients dans un corps. Cet espace vectoriel, de dimension infinie, est largement utilisé en algèbre linéaire, à travers par exemple le [[polynôme minimal d'un endomorphisme|polynôme minimal]] ou [[polynôme caractéristique|caractéristique]]. Le [[polynôme d'endomorphisme|morphisme canonique]] entre les polynômes et les applications linéaires d'un espace vectoriel est à l'origine d'une structure d'algèbre qui est un anneau, si la multiplication externe est ''oubliée''.

Cette méthode permet d'élucider la structure de certains anneaux. Tout anneau est un espace vectoriel sur ceux de ses sous-anneaux qui sont des corps. L'espace vectoriel ressemble à la structure développée par Grassman. Cette remarque est utilisée au début du {{s-|XX}}, en particulier par [[Emil Artin]] et [[Emmy Noether]], pour élucider cette structure dans le cas des anneaux artiniens et [[Anneau noethérien|noethériens]], qui sont des copies de sous-algèbres sur un espace vectoriel construit sur sous-anneau qui s'avère être un corps.

Un exemple est la généralisation d'un théorème de [[Joseph Henry Maclagan Wedderburn|Wedderburn]] par Artin et portant maintenant le nom de [[théorème d'Artin-Wedderburn]]. Il est important en [[algèbre non commutative]].

[[Anneau opposé|Un lemme élémentaire]] permet par ailleurs d'interpréter le corps des [[quaternion]]s comme l'algèbre des [[Représentation de groupe#Définitions|endomorphismes]] d'[[Quaternion#Représentation des quaternions comme matrices 4x4 de nombres réels|une représentation réelle de degré 4]] du [[groupe des quaternions|groupe associé]].

=== Théorie de Galois ===
{{Article détaillé|Théorie de Galois}}
[[Fichier:Pentagone construit.png|thumb|La théorie de Galois permet de déterminer quels polygones réguliers sont constructibles à la règle et au compas. [[Construction du pentagone régulier à la règle et au compas|Le pentagone en fait partie]].]]
La théorie de Galois contient de nombreux exemples d'espaces vectoriels. Elle consiste à étudier un corps comme un espace vectoriel sur un sous-corps. Ainsi chaque sous-corps permet de considérer la structure initiale comme un espace vectoriel particulier.

Un exemple d'application est celui des figures [[construction à la règle et au compas|constructible à la règle et au compas]]. Ces points forment un corps disposant d'une structure d'espace vectoriel sur les nombres rationnels. Il est de dimension infinie et, pour chaque point, le plus petit sous-corps le contenant est de dimension finie égale à une puissance de 2. Un tel sous-corps est appelé une [[tour d'extensions quadratiques]]. Cette propriété de ces espaces vectoriels permet de résoudre d'antiques conjectures comme la [[duplication du cube]], la [[trisection de l'angle]] ou la construction d'un [[polygone régulier]].

L'exemple historique de la théorie est celui de la résolution d'une [[équation algébrique|équation polynomiale]]. Le [[Théorème d'Abel (algèbre)|théorème d'Abel]] donne une condition nécessaire et suffisante de résolution par [[Racine d'un nombre#Racines d'un complexe|radicaux]]. Les espaces vectoriels utilisés ont pour éléments ceux du plus petit corps ''L'' contenant tous les coefficients du polynôme ainsi que ses racines et le corps sous-jacent est un sous-corps ''K'' du premier contenant tous les coefficients. Le [[groupe de Galois]] est composé des automorphismes du corps ''L'' et laissant invariant le corps ''K''. Il correspond à un nombre fini de [[symétrie]]s de l'espace vectoriel. {{Refnec|date=mars 2013|L'élément clé de la démonstration montre que l'équation est résoluble seulement si ces symétries sont [[Diagonalisation|diagonalisables]].}}

==Notes et références==

{{Références}}

== Bibliographie ==
* Vincent Blanloeil: ''Une introduction moderne à l’algèbre linéaire''. Ellipses, 2012.
* Roger Mansuy, Rached Mneimné: ''Algèbre linéaire - Réduction des endomorphismes''. Vuibert, 2012.

== Voir aussi ==
{{Autres projets
|commons=Category:Linear algebra
|wikt=algèbre linéaire
|b=Algèbre linéaire
|v=Algèbre linéaire
}}
===Articles connexes===
* [[Propriétés métriques des droites et plans]]
* [[Algèbre multilinéaire]]
=== Liens externes ===
* {{en}} [http://www.egwald.com/linearalgebra/index.php Linear Algebra] par Elmer G. Wiens
* [http://web.archive.org/web/20101108172830/http://roso.epfl.ch/teaching.html Les cours du ROSO, dont de l'Algèbre linéaire]
* [http://braise.univ-rennes1.fr/  Braise : la base raisonnée d'exercices de mathématiques et son chapitre sur l'Algèbre linéaire]

{{Palette|Algèbre linéaire|Domaines des mathématiques}}
{{Portail|Algèbre}}

{{DEFAULTSORT:Algebre lineaire}}
[[Catégorie:Algèbre linéaire| ]]</text>
      <sha1>4o7gtmfd7y90eg8c2vluxktap8b0i3c</sha1>
    </revision>
  </page>
  <page>
    <title>Algèbre générale</title>
    <ns>0</ns>
    <id>9</id>
    <revision>
      <id>139343664</id>
      <parentid>137420672</parentid>
      <timestamp>2017-07-30T02:32:32Z</timestamp>
      <contributor>
        <username>Gaétan Lui Même</username>
        <id>2536193</id>
      </contributor>
      <minor />
      <comment>/* Histoire */  syntaxr</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{Voir homonymes|Algèbre (homonymie)}}
{{Ébauche|algèbre}}
L''''algèbre générale''', ou '''algèbre abstraite''', est la branche des [[mathématiques]] qui porte principalement sur l'étude des [[structure algébrique|structures algébriques]] et de leurs relations. L'appellation ''algèbre générale'' s'oppose à celle d'''[[Algèbre (mathématiques élémentaires)|algèbre élémentaire]]'' ; cette dernière enseigne le [[calcul algébrique]], c'est-à-dire les règles de manipulation des [[équation algébrique|formules]] et des [[expressions algébriques]].

Historiquement, les structures algébriques sont apparues dans différents domaines des mathématiques, et n'y ont pas été étudiées séparément. C'est pourquoi l'algèbre générale possède beaucoup de connexions avec toutes les branches des mathématiques.

L'étude des structures algébriques peut être faite de manière abstraite, mais unifiée dans le cadre de l'[[algèbre universelle]].

== Histoire ==
Comme dans d'autres parties des mathématiques, des problèmes et des exemples concrets ont joué un rôle important dans le développement de l'algèbre abstraite. Jusqu'à la fin du {{s-|XIX}}, beaucoup - ou plus - de ces problèmes étaient en quelque sorte liés à la théorie des [[Équation algébrique|équations algébriques]]. Les principaux thèmes sont les suivants:
* Résolution de systèmes d'[[Équation linéaire|équations linéaires]], ce qui a conduit à l'[[algèbre linéaire]]
* Tentatives de trouver des formules aux solutions d'[[Équation polynomiale|équations polynomiales]] générales de degré supérieur qui ont abouti à la découverte de [[Groupe de Galois|groupes]] comme des manifestations abstraites de [[symétrie]]
* Études arithmétiques des formes de degré quadratique supérieur et des [[Équation diophantienne|équations diophantiennes]], qui ont produit directement les notions d'un [[Anneau (mathématiques)|anneau]] et [[Idéal (mathématiques)|idéal]].

=== Algèbre moderne ===
La fin du {{19e}} et le début du {{s-|XX}} a connu un énorme changement dans la méthodologie des mathématiques. L'algèbre abstraite a émergé autour du début du {{s-|XX}}, sous le nom de l'''algèbre moderne''. Son étude faisait partie de l'entraînement pour plus de [[Rigueur|rigueur intellectuelle]] en mathématiques. Les définitions officielles de certaines [[Structure algébrique|structures algébriques]] ont émergé au {{s-|XIX}}.

== Applications ==
En raison de sa généralité, l'algèbre abstraite est utilisée dans de nombreux domaines des mathématiques et de la science. Par exemple, la [[topologie algébrique]] utilise des objets algébriques pour son étude. La [[théorie algébrique des nombres]] étudie divers anneaux numériques qui généralisent l'ensemble des entiers. En utilisant la théorie des nombres algébriques, [[Andrew Wiles]] a prouvé le [[dernier théorème de Fermat]].

== Bases ==
* [[Théorie des ensembles]]
** [[Ensemble|Notion d'ensemble]]
** [[Sous-ensemble]]
** [[Opérations sur les ensembles]]
** [[Produit cartésien]]
*Correspondances et relations
** [[Relation binaire]]
** [[Fonction et application|Fonctions et applications]]
* [[Loi de composition]]
** [[Loi de composition interne|Loi interne]]

== Structures algébriques ==
{{article détaillé|Structure algébrique}}
* [[Magma (mathématiques)|Magma]]
* [[Demi-groupe]] (ou semi-groupe)
* [[Quasigroupe]]
* [[Monoïde]]
* [[Groupe (mathématiques)|Groupe]]
* [[Anneau unitaire|Anneau]]
* [[Module sur un anneau|Module]]
* [[Corps (mathématiques)|Corps]]
* [[Corps commutatif]]
* [[Espace vectoriel]]
* [[Algèbre sur un anneau]]
* [[Algèbre sur un corps]]
* [[Opérade]]

== Articles connexes ==
* [[Évariste Galois]] et [[Niels Henrik Abel]] (mathématiciens ayant fourni un travail majeur pour la construction de l'algèbre)
* [[Emmy Noether]] 
* [[Théorie des codes]]
* [[Théorie des groupes]]
{{Palette Domaines des mathématiques}}

{{Portail|algèbre}}

{{DEFAULTSORT:Algebre generale}}

[[Catégorie:Algèbre générale| ]]</text>
      <sha1>gev14io4wyeug2zqx9cl5nzalloap3x</sha1>
    </revision>
  </page>
  <page>
    <title>Algorithmique</title>
    <ns>0</ns>
    <id>10</id>
    <revision>
      <id>139980237</id>
      <parentid>138889046</parentid>
      <timestamp>2017-08-22T20:57:13Z</timestamp>
      <contributor>
        <username>Anne Bauval</username>
        <id>474773</id>
      </contributor>
      <minor />
      <comment>/* Articles connexes */ -lien redondant + màj intitulé</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">[[Fichier:Euclid flowchart 1.png|thumb|[[Organigramme de programmation]] représentant l'[[algorithme d'Euclide]].]]
L{{'}}'''algorithmique''' est l'étude et la production de règles et techniques qui sont impliquées dans la définition et la conception d'[[algorithme]]s, c'est-à-dire de processus systématiques de résolution d'un problème permettant de décrire précisément des étapes pour résoudre un [[problème algorithmique]]. 

== Étymologie ==
Le mot « algorithme » vient du nom du [[mathématicien]] [[Al-Khwârizmî]]&lt;ref&gt;{{Lien web|auteur1=Phillipe Collard |auteur2=[[Philippe Flajolet]]|titre=Algorithmique |url=http://www.universalis.fr/encyclopedie/algorithmique/ |date= |site=Encyclopædia universalis |consulté le=8 mars 2015}}.&lt;/ref&gt; (latinisé au Moyen Âge en {{lang|la|''Algoritmi''}}), qui, au {{IXe siècle}} écrivit [[Abrégé du calcul par la restauration et la comparaison|le premier ouvrage systématique]] donnant des solutions aux [[équation linéaire|équations linéaires]] et [[équation du second degré|quadratiques]].  « Algorithme » a donné « algorithmique » auxquels certains préfèrent le néologisme « algorithmie ».

== Histoire ==
=== Antiquité ===
Les premiers algorithmes dont on a retrouvé des descriptions datent des [[Babylone|Babyloniens]], au {{-millénaire|III|e}}. Ils décrivent des méthodes de [[Calcul (mathématiques)|calcul]] et des résolutions d'équations à l'aide d'exemples.

Un algorithme célèbre est celui qui se trouve dans le livre 7 des ''[[algorithme d'Euclide|Éléments d'Euclide]]'', et appelé [[algorithme d'Euclide]]. Il permet de trouver le plus grand diviseur commun, ou [[Plus grand commun diviseur|PGCD]], de deux nombres. Un point particulièrement remarquable est qu’il contient explicitement une [[itération]] et que les propositions 1 et 2 démontrent sa [[correction d'un algorithme|correction]].

C'est [[Archimède]] qui proposa le premier un algorithme pour le calcul de {{math|[[π]]}}&lt;ref&gt;Le calcul de {{math|π}} {{citation|est caractéristique des problèmes generaux rencontrés en algorithmique.}} {{Lien web|auteur1=Phillipe Collard |auteur2=Phillipe Flajolet|titre=Algorithmique|sous-titre=1. L'exemple du calcul de {{math|π}}|url=http://www.universalis.fr/encyclopedie/algorithmique/1-l-exemple-du-calcul-de-p|date= |site=[[Encyclopædia universalis]] |consulté le=8 mars 2015}}.&lt;/ref&gt;.

=== Étude systématique ===
Le premier à avoir systématisé des algorithmes est le mathématicien [[perse]] [[Al-Khwârizmî]], actif entre 813 et 833. Dans son ouvrage ''[[Abrégé du calcul par la restauration et la comparaison]]'', il étudie toutes les [[équation du second degré|équations du second degré]] et en donne la résolution par des algorithmes généraux. Il utilise des méthodes semblables à celles des [[Mathématiques babyloniennes|Babyloniens]], mais se différencie par ses explications systématiques là où les Babyloniens donnaient seulement des exemples.

Le savant [[Al-Andalus|andalou]] [[Averroès]] ([[1126]]-[[1198]]) évoque une méthode de raisonnement où la thèse s’affine étape par étape, itérativement, jusqu’à une certaine convergence et ceci conformément au déroulement d’un algorithme. À la même époque, au {{XIIe siècle}}, le moine [[Adelard de Bath]] introduit le terme [[latin]] de {{lang|la|''algorismus''}}, par référence au nom de Al Khuwarizmi. Ce mot donne ''algorithme'' en [[français]] en [[1554]].

Au {{XVIIe siècle}}, on pourrait entrevoir une certaine allusion à la méthode algorithmique chez [[René Descartes]] dans la méthode générale proposée par le [[Discours de la méthode]] ([[1637]]), notamment quand, en sa deuxième partie, le mathématicien français propose de {{citation|diviser chacune des difficultés que j’examinerois, en autant de parcelles qu’il se pourroit, et qu’il seroit requis pour les mieux résoudre.}} Sans évoquer explicitement les concepts de boucle, d’itération ou de dichotomie, l’approche de Descartes prédispose la logique à accueillir le concept de programme, mot qui naît en français en [[1677]].

L’utilisation du terme ''algorithme'' est remarquable chez [[Ada Lovelace]], fille de [[Lord Byron]] et assistante de [[Charles Babbage]] ([[1791]]-[[1871]]).

=== L'époque contemporaine ===

L’algorithmique du {{s2-|XX|e|XXI}} se base souvent sur des formalismes comme celui des [[machines de Turing]], qui permettent de définir précisément ce qu'on entend par &quot;étapes&quot;, par &quot;précis&quot; et par &quot;non ambigu&quot; et elle donne un cadre scientifique pour étudier les propriétés des algorithmes. Cependant, le type de formalisme choisi engendre  des algorithmes différents pour résoudre un même problème, par exemple l'[[Algorithme récursif|algorithmique récursive]], l'[[algorithme parallèle|algorithmique parallèle]] ou l’[[informatique quantique]] donnent lieu à des algorithmes différents de ceux de l'algorithmique itérative issue de la machine de Turing.

Avec l'informatique, l'algorithmique s'est beaucoup développée dans la deuxième moitié du {{s-|XX}} et [[Donald Knuth]], auteur du traité ''[[The Art of Computer Programming]]'', qui décrit de très nombreux algorithmes, en a posé des fondements mathématiques rigoureux de leur analyse.

== Vocabulaire ==
Le substantif ''algorithmique'' désigne l'ensemble des méthodes permettant de créer des algorithmes. Le terme est également employé comme adjectif.

Un ''algorithme'' énonce une solution à un problème sous la forme d’un enchaînement d’''opérations à effectuer''.

Les informaticiens utilisent fréquemment l’anglicisme ''implémentation'' pour désigner la mise en œuvre de l'algorithme dans un [[langage de programmation]] . Cette implémentation réalise la transcription des opérations constitutives  de l’algorithme et  précise la façon dont ces opérations sont invoquées. Cette écriture en langage informatique, est aussi fréquemment désignée par le terme de « ''[[codage (programmation)|codage]]''&lt;Ref&gt; , en [[cryptographie]] le terme codage est utilisé dans un sens différent, &lt;/ref&gt; ». On parle de ''« [[code source]] »'' pour désigner le texte, constituant le programme, réalisant l’algorithme. Le ''code'' est plus ou moins détaillé selon le niveau d’abstraction du langage utilisé, de même qu'une recette de cuisine doit être plus ou moins détaillée selon l’expérience du cuisinier.

== Étude formelle ==
De nombreux outils formels ou théoriques ont été développés pour décrire les algorithmes, les étudier, exprimer leurs qualités, pouvoir les comparer :
* Ainsi, pour décrire les algorithmes, des structures algorithmiques ont été mises en évidence : structures de contrôle et structures de données.
* Pour justifier de la qualité des algorithmes, les notions de correction, de complétude et de terminaison ont été mises en place.
* Enfin, pour comparer les algorithmes, une théorie de la complexité des algorithmes a été définie.

=== Structures algorithmiques ===

Les concepts en œuvre en algorithmique, par exemple selon l'approche de [[Niklaus Wirth|N. Wirth]] pour les langages les plus répandus (Pascal, C, etc.), sont en petit nombre. Ils appartiennent à deux classes :
* les [[structure de contrôle|structures de contrôle]]
** séquences
** conditionnelles 
** boucles
* les [[Structure de données|structures de données]]
** constantes
** variables 
** tableaux
** structures récursives (listes, arbres, graphes)

Ce découpage est parfois difficile à percevoir pour certains langages ([[Lisp]], [[Prolog]]…) plus basés sur la notion de [[algorithme récursif|récursivité]] où certaines structures de contrôle sont implicites et, donc, semblent disparaître.

=== Correction, complétude, terminaison ===

Ces trois notions « correction », « complétude », « terminaison » sont liées, et supposent qu'un algorithme est écrit pour résoudre un problème.

La [[Terminaison d'un algorithme|terminaison]] est l'assurance que l'algorithme terminera en un temps fini. Les preuves de terminaison font habituellement intervenir une fonction entière positive strictement décroissante à chaque « pas » de l'algorithme.

Étant donnée la garantie qu'un algorithme terminera, la preuve de correction doit apporter l'assurance que si l'algorithme termine en donnant une proposition de solution, alors cette solution est correcte — c'est-à-dire qu'elle est effectivement une solution au problème posé.

La preuve de complétude garantit que, pour un espace de problèmes donné, l'algorithme, s'il termine, donnera une solution pour chacune des entrées.

=== Complexité algorithmique ===

{{Article détaillé|Théorie de la complexité des algorithmes}}

Les principales notions mathématiques dans le calcul du coût d’un algorithme précis sont les [[notation de Landau|notions de domination]] (notée ''O(f(n))'', « grand o »), où ''f'' est une [[fonction mathématique]] de ''n'', variable désignant la quantité d’informations (en [[bit]]s, en nombre d’enregistrements, etc.) manipulée dans l’algorithme. En algorithmique on trouve souvent des complexités du type :

{| class=&quot;wikitable&quot;
! Notation
! Type de complexité
|-
| &lt;math&gt;O(1)&lt;/math&gt;
| complexité constante (indépendante de la taille de la donnée)
|-
| &lt;math&gt;O(\log(n))&lt;/math&gt;
| complexité logarithmique
|-
| &lt;math&gt;O(n)&lt;/math&gt;
| complexité linéaire
|-
| &lt;math&gt;O(n \log(n))&lt;/math&gt;
| complexité quasi-linéaire
|-
| &lt;math&gt;O(n^{2})&lt;/math&gt;
| complexité quadratique
|-
| &lt;math&gt;O(n^{3})&lt;/math&gt;
| complexité cubique
|-
| &lt;math&gt;O(n^p)&lt;/math&gt;
| complexité polynomiale
|-
| &lt;math&gt;O(n^{\log(n)})&lt;/math&gt;
| complexité quasi-polynomiale
|-
| &lt;math&gt;O(2^{n})&lt;/math&gt;
| complexité exponentielle
|-
| &lt;math&gt;O(n!)&lt;/math&gt;
| complexité factorielle
|}

Sans entrer dans les détails mathématiques, le calcul de l’efficacité d’un algorithme (sa ''[[Théorie de la complexité (informatique théorique)|complexité algorithmique]]'') consiste en la recherche de deux quantités importantes. La première quantité est l’évolution du nombre d’instructions de base en fonction de la quantité de données à traiter (par exemple, pour un [[algorithme de tri]], il s'agit du nombre de données à trier), que l’on privilégiera sur le temps d'exécution mesuré en secondes (car ce dernier dépend de la machine sur laquelle l'algorithme s'exécute). La seconde quantité estimée est la quantité de mémoire nécessaire pour effectuer les calculs. Baser le calcul de la complexité d’un algorithme sur le temps ou la quantité effective de mémoire qu’un ordinateur particulier prend pour effectuer ledit algorithme ne permet pas de prendre en compte la structure interne de l’algorithme, ni la particularité de l’ordinateur : selon sa charge de travail, la vitesse de son processeur, la vitesse d’accès aux données, l’exécution de l’algorithme (qui peut faire intervenir le hasard) ou son organisation de la mémoire, le temps d’exécution et la quantité de mémoire ne seront pas les mêmes.

Souvent, on examine les performances &quot;au pire&quot;, c'est-à-dire dans les configurations telles que le [[complexité en temps|temps d'exécution]] ou l'[[complexité en espace|espace mémoire]] est le plus grand. Il existe également un autre aspect de l'évaluation de l'efficacité d'un algorithme : les performances &quot;en moyenne&quot;. Cela suppose d'avoir un modèle de la répartition statistique des données de l'algorithme, tandis que la mise en œuvre des techniques d'analyse implique des méthodes assez fines de [[analyse combinatoire|combinatoire]] et d'[[Développement asymptotique|évaluation asymptotique]], utilisant en particulier les [[série génératrice|séries génératrices]] et des méthodes avancées d'[[analyse complexe]]. L'ensemble de ces méthodes est regroupé sous le nom de [[combinatoire analytique]].

On trouvera dans l’article sur la [[théorie de la complexité des algorithmes]] d’autres évaluations de la complexité qui vont en général au-delà des valeurs proposées ci-dessus et qui répartissent les problèmes (plutôt que les algorithmes) en classes de complexité.

==== Quelques indications sur l’efficacité des algorithmes ====

Souvent, l’efficacité d’un algorithme n’est connue que de manière asymptotique, c’est-à-dire pour de grandes valeurs du paramètre ''n''.
Lorsque ce paramètre est suffisamment petit, un algorithme de complexité asymptotique plus grande peut en pratique être plus efficace.
Ainsi, pour trier un tableau de 30&amp;nbsp;lignes (c’est un paramètre de petite taille), il est inutile d’utiliser un algorithme évolué comme le [[tri rapide]] (l’un des algorithmes de tri asymptotiquement les plus efficaces en moyenne) : l’algorithme de tri le plus simple à écrire sera suffisamment efficace.

Entre deux algorithmes dont la complexité est identique, on cherchera à utiliser celui dont l’occupation mémoire est la plus faible. L’analyse de la complexité algorithmique peut également servir à évaluer l’occupation mémoire d’un algorithme. Enfin, le choix d’un algorithme plutôt qu’un autre doit se faire en fonction des données que l’on s’attend à lui fournir en entrée. Ainsi, le  [[tri rapide]], lorsque l’on choisit le premier élément comme pivot, se comporte de façon désastreuse si on l’applique à une liste de valeurs déjà triée. Il n’est donc pas judicieux de l’utiliser si on prévoit que le programme recevra en entrée des listes déjà presque triées ou alors il faudra choisir le pivot aléatoirement.

Un autre paramètre à prendre en compte est la [[Mémoire virtuelle#Principe de localité|localité]] de l’algorithme. Par exemple pour un système à [[mémoire virtuelle]] qui dispose de peu de mémoire vive (par rapport au nombre de données à traiter), le [[tri rapide]] sera normalement plus efficace que le [[tri par tas]] car le premier ne passe qu’une seule fois sur chaque élément de la mémoire tandis que le second accède à la mémoire de manière discontinue (ce qui augmente le risque de {{lang|en|''[[Mémoire virtuelle#Swapping|swapping]]''}}).

Enfin, il existe certains algorithmes dont l'analyse de complexité est dite [[analyse amortie|amortie]]. Cela signifie que, pour certaines exécutions de l’algorithme (cas marginaux), la complexité de l’algorithme sera très supérieure au cas moyen, mais sera compensée par des exécutions rendues efficaces du même algorithme dans une suite d'invocations de cet algorithme.

L'[[Analyse lisse d'algorithme|analyse lisse]] mesure les performances des algorithmes sur les pires cas, mais avec une légère perturbation des instances.  Elle permet d'expliquer pourquoi des algorithmes analysés comme inefficaces autrement sont en fait efficaces en pratique.  L'[[algorithme du simplexe]] est un exemple d'un algorithme qui se comporte bien pour l'analyse lisse.

== Approches pratiques ==

L'algorithmique a développé quelques stratégies pour résoudre les problèmes :
* [[algorithme glouton]] : un premier algorithme peut souvent être proposé en étudiant le problème très progressivement : on résout chaque sous-problème localement en espérant que l'ensemble de leurs résultats composera bien une solution du problème global. On parle alors d'algorithme glouton. L'algorithme glouton n'est souvent qu'une première étape dans la rédaction d'un algorithme plus performant ;
* [[Diviser pour régner (informatique)|diviser pour régner]] : pour améliorer les performances des algorithmes, une technique usuelle consiste à diviser les données d'un problème en sous-ensembles de tailles plus petites, jusqu'à obtenir des données que l'algorithme pourra traiter au cas par cas. Une seconde étape dans ces algorithmes consiste à « fusionner » les résultats partiels pour obtenir une solution globale. Ces algorithmes sont souvent associés à la récursivité ;
* [[recherche exhaustive]] (ou combinatoire) : une méthode utilisant l'énorme puissance de calcul des ordinateurs consiste à regarder tous les cas possibles. Cela n'est pour autant possible que dans certains cas particuliers (la combinatoire est souvent plus forte que l'énorme puissance des ordinateurs, aussi énorme soit-elle) ;
* décomposition top-down / bottom-up : (décomposition descendante, décomposition remontante)  les décompositions top-down consistent à essayer de décomposer le problème en sous-problèmes à résoudre successivement, la décomposition allant jusqu'à des problèmes triviaux faciles à résoudre. L'algorithme global est alors donné par la composée des algorithmes définis au cours de la décomposition. La démarche bottom-up est la démarche inverse, elle consiste à partir d'algorithmes simples, ne résolvant qu'une étape du problème, pour essayer de les composer pour obtenir un algorithme global ;
* pré-traitement / post-traitement : parfois, certains algorithmes comportent une ou deux phases identifiées comme des pré-traitements (à faire avant l'algorithme principal), ou post-traitement (à faire après l'algorithme principal), pour simplifier l'écriture de l'algorithme général ;
* [[programmation dynamique]] : elle s'applique lorsque le problème d'optimisation est composé de plusieurs sous-problèmes de même nature, et qu'une solution optimale du problème global s'obtient à partir de solutions optimales des sous-problèmes.

=== Les heuristiques ===
{{article détaillé| Algorithme de Las Vegas|Algorithme de Monte-Carlo}}

Pour certains problèmes, les algorithmes ont une complexité beaucoup trop grande pour obtenir un résultat en temps raisonnable, même si l’on pouvait utiliser une puissance de calcul phénoménale. On est donc amené à rechercher la  solution de façon non systématique ([[algorithme de Las Vegas]]) ou de se contenter d'une solution la plus proche possible d’une solution optimale en procédant par essais successifs ([[algorithme de Monte-Carlo]]). Puisque toutes les combinaisons ne peuvent être essayées, certains choix stratégiques doivent être faits. Ces choix, généralement très dépendants du problème traité, constituent ce qu’on appelle une [[heuristique (mathématiques)|heuristique]]. Le but d’une heuristique n'est donc pas d'essayer toutes les combinaisons possibles, mais de trouver une solution en un temps raisonnable et par un autre moyen, par exemple en procédant à des tirages aléatoires. La solution peut être exacte (Las Vegas) ou approchée  (Monte-Carlo).  Les ''algorithmes d'Atlantic City'' quant à eux donnent de façon probablement efficace une réponse probablement juste (disons avec une chance sur cent millions de se tromper) à la question posée.

C’est ainsi que les programmes de [[Échecs|jeu d’échecs]] ou de [[jeu de go]] (pour ne citer que ceux-là) font appel de manière très fréquente à des heuristiques qui modélisent l’expérience d’un joueur. Certains [[Logiciel antivirus|logiciels antivirus]] se basent également sur des heuristiques pour reconnaître des [[virus informatique]]s non répertoriés dans leur base, en s’appuyant sur des ressemblances avec des virus connus, c'est un exemple d'algorithme d'Atlantic City. De même le [[problème SAT]] qui est l'archétype du [[problème NP-complet]] donc très difficile est résolu de [[Problème SAT#Algorithmes de SAT|façon pratique et efficace par la mise au point d'heuristiques]]&lt;ref&gt;{{en}} Moshe Vardi, ''{{Langue|en|Boolean Satisfiability: Theory and Engineering}}'' [http://cacm.acm.org/magazines/2014/3/172516-boolean-satisfiability/fulltext (Communications of the ACM, Vol. 57 No. 3, Page 5)].&lt;/ref&gt;.

== Exemples d’algorithmes, de problèmes, d'applications ou domaines d'application ==

Il existe un certain nombre d’algorithmes classiques, utilisés pour résoudre des problèmes ou plus simplement pour illustrer des méthodes de programmation. On se référera aux articles suivants pour de plus amples détails (voir aussi [[liste des algorithmes]]) :
* Algorithmes ou problèmes classiques (du plus simple ou plus complexe)
** échange, ou comment échanger les valeurs de deux variables : problème classique illustrant la notion de variable informatique (voir aussi [[Structure de données]])
** Algorithmes de recherche, ou comment retrouver une information dans un ensemble structuré ou non (par exemple [[Recherche dichotomique]])
** [[algorithme de tri]], ou comment trier un ensemble de nombres le plus rapidement possible ou en utilisant le moins de ressources possible
** [[problème du voyageur de commerce]], [[problème du sac à dos]], [[problème SAT]] et autres algorithmes ou approximations de solutions pour les problèmes combinatoires difficiles (dit NP-complets) 
* Algorithmes ou problèmes illustrant la programmation récursive (voir aussi [[algorithme récursif]])
** [[tours de Hanoï]]
** [[huit dames]], placer huit dames sur un échiquier sans qu’elles puissent se prendre entre elles,
** [[suite de Conway]],
** algorithme de dessins récursifs ([[fractale]]) pour le [[Tapis de Sierpiński]], la [[Courbe du dragon]], le [[Flocon de Koch]]…
* Algorithmes dans le domaine des mathématiques
** calcul de la [[factorielle]] d'un nombre, de la [[Fonction d'Ackermann]] ou de la [[suite de Fibonacci]],
** [[algorithme du simplexe]], qui minimise une fonction linéaire de variables réelles soumises à des contraintes linéaires,
** [[fraction continue d'un nombre quadratique]], permettant d'extraire une [[racine carrée]], cas particulier de la [[méthode de Newton]]
** dans le domaine de l'algèbre : l'[[unification|algorithme d'unification]],  le calcul d'une [[bases de Gröbner|base de Gröbner]] d'un idéal de polynôme et plus généralement presque toutes les méthodes de [[calcul symbolique]],
** en [[Théorie des graphes#Aspect algorithmique|théorie des graphes]] qui donne lieu à de nombreux algorithmes,
** [[test de primalité]].
* Algorithmes pour et dans le domaine de l'informatique
** [[cryptologie]] et [[compression de données]]
** [[Informatique musicale]]
** [[algorithme génétique]] en [[informatique décisionnelle]]
** Analyse et compilation des langages formels (voir [[Compilateur]] et [[Interprète (informatique)]])
** [[allocation de mémoire]] ([[ramasse-miettes (informatique)|ramasse-miettes]])

== Annexes ==
{{Autres projets
|wiktionary=algorithmie
|wikiversity=Algorithmique
|wikibooks=Algorithmique impérative}}

=== Notes et références ===
{{Références}}

=== Bibliographie ===
* {{Ouvrage|langue=en|titre=[[The Art of Computer Programming]]|auteur1=[[Donald Knuth|Donald E. Knuth]]|volume=2|titre volume=Seminumerical algorithms|lieu=Reading, Mass|éditeur=Addison-Wesley Pub. Co|année=1973|pages totales=764|isbn=978-0-201-89684-8|isbn2=978-0-321-75104-1|oclc=781024586}}
* {{Algorithmique (Quercia)}}
* {{Cormen3fr}}

=== Liens externes ===
* [http://interstices.info/algo Qu’est-ce qu'un algorithme ?] par [[Philippe Flajolet]] et Étienne Parizot sur la revue en ligne [[Interstices]]

=== Articles connexes ===
* [[Algorithme récursif]]
* [[Algorithme réparti]]
* [[Algorithme émergent]]
* [[Algorithme adaptatif]]
* [[Art algorithmique]]
* [[Liste d'algorithmes]]
* [[Métaheuristique]]
* [[Recherche opérationnelle]]

{{Palette
| Informatique théorique
}}

{{Portail|informatique théorique}}

[[Catégorie:Algorithmique|*]]</text>
      <sha1>00htio3wtdu8b7fqrdlh5sw6t54chdy</sha1>
    </revision>
  </page>
  <page>
    <title>Politique en Argentine</title>
    <ns>0</ns>
    <id>11</id>
    <revision>
      <id>139679853</id>
      <parentid>139679499</parentid>
      <timestamp>2017-08-11T20:18:26Z</timestamp>
      <contributor>
        <username>Celette</username>
        <id>418936</id>
      </contributor>
      <comment>/* Mandat de Mauricio Macri */ C'est également HS sur cette page. Dans ce cas, créer un article &quot;Présidence de Mauricio Macri&quot; (je ne me prononce même pas sur le fond en général mais sur le fait que ça n'a rien à faire ici). Il y a une PdD.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve">{{ébauche|Politique|Argentine}}
L'[[Argentine]] est une [[république]] [[régime présidentiel|présidentielle]] [[multipartisme|multipartite]], où le président est à la fois [[chef de l'État]] et chef du [[gouvernement]]. Le [[pouvoir exécutif]] est détenu par le gouvernement et le [[pouvoir législatif]] est partagé entre le gouvernement et les deux chambres du [[parlement]]. Le pouvoir judiciaire est indépendant des deux premiers.

== Pouvoir exécutif ==

Les élections présidentielles se déroulent en un ou deux tours. Si aucun candidat ne récolte plus de 45 % des votes, alors un deuxième tour est organisé. Seuls les deux candidats qui ont remporté le plus de votes participent au deuxième tour (2003). [[Histoire de l'Argentine|Historiquement]], le pays est marqué par le [[bipartisme]] entre le [[Parti justicialiste]] (ou [[péroniste]]), qui fut cependant interdit de 1955 aux [[élections de 1973 (Argentine)|élections de 1973]], puis à nouveau réprimé après le [[coup d'Etat de mars 1976]], et le parti radical ([[Union Civique Radicale]], UCR) et l'élection se fait normalement dès le premier tour.

Depuis 1989, il n'y eut aucun débat télévisé entre deux candidats à la présidentielle [http://www.monografias.com/trabajos31/politicos-calle-conferencias-partido-socialista/politicos-calle-conferencias-partido-socialista.pdf].

== Histoire ==

19 candidats étaient inscrits pour les élections du {{date|19|avril|2003}}, fait exceptionnel et un second tour était attendu.

=== Élection présidentielle 2003 ===

Les 19 candidats étaient (dans l'ordre alphabétique) :

# [[Jorge Altamira]]
# [[Juan Carlos Arcagni]]
# [[José Bonacci]]
# [[Alfredo Bravo]]
# [[Elisa Carrió]]
# [[Manuel Herrera]]
# [[Néstor Kirchner]]
# [[Manuel Manusovich]]
# [[Mario Mazzitelli]]
# [[Carlos Menem]]
# [[Leopoldo Moreau]]
# [[Ricardo López Murphy]]
# [[Ricardo Mussa]]
# [[Gustavo Breide Obeid]]
# [[Adolfo Rodríguez Saá]]
# [[Guillermo Sulling]]
# [[Enrique Venturino]]
# [[Patricia Walsh]]
# [[Carlos Zaffore]]

[[Carlos Menem]], ancien président est arrivé en tête au premier tour avec 24 % des voix, suivi de [[Néstor Kirchner]], proche du président en titre, [[Eduardo Duhalde]], avec 22 %. Tous les deux sont issus du parti justicialiste ([[péronisme|péroniste]]). [[Carlos Menem]], d'après les sondages, ne paraissait pas pouvoir significativement progresser par rapport à son score du premier tour et semblait donc promis à une lourde défaite, avec 30 % de retard. Il a renoncé le [[14 mai]], à quatre jours du second tour, laissant Nestor Kirchner devenir automatiquement président. Les adversaires de Menem et notamment l'entourage du président Duhalde ont qualifié cette décision d'irresponsable, puisqu'en privant Kirchner de la victoire au second tour, en faisant un président par défaut, elle pourrait miner sérieusement sa légitimité…

=== Mandat de Nestor Kirchner ===
Une fois élu à la tête de l'Argentine, [[Nestor Kirchner]] a eu devant lui un chantier imposant : reconstruire l'économie de l'Argentine, gravement endommagée par la [[crise économique argentine|crise financière de 2001]]. Il tente d'appliquer à l'Argentine les recettes qui ont fait le succès économique de la province de [[Santa Cruz (province argentine)|Santa Cruz]], en Patagonie, dont il était le gouverneur jusqu'en 2003.
Ses premières tâches ont été :
* la renégociation de la dette en défaut, avec le [[FMI]] et avec les créanciers privés. Un accord a été trouvé avec ces derniers début 2005, ceux-ci devant renoncer à 75 % de leurs créances.
* les renégociations des contrats d'eau et de gaz avec de grandes entreprises étrangères (Suez…). La plupart des services publics ont été privatisés pendant l'ère Menem.
* les discussions avec les « [[piqueteros]] », associations de chômeurs bloquant régulièrement les routes pour demander la revalorisation des aides sociales.

Nestor Kirchner a également été confronté à une vague de violences et d'enlèvements (contre rançons), avec l'implication de la police de la Province de Buenos Aires. Il a donc mené une épuration de la police et de la justice pour lutter contre la corruption et la violence organisée, et nomma en juin 2004 [[Esteban Righi]], l'ex-ministre de l'Intérieur d'[[Héctor Cámpora]] (mai-juillet 1973), [[procureur général|procureur de la Nation]]&lt;ref name=Clarin&gt;Julio Blanck, [http://www.clarin.com/suplementos/zona/2004/06/06/z-03301.htm Esteban Righi, un hombre marcado por sus palabras], ''[[El Clarín]]'', 6 juin 2004&lt;/ref&gt;.

Les [[élections générales argentines de 2007|élections générales de 2007]] ont été à nouveau remportées par le [[Parti justicialiste]], portant la femme de Kirchner, [[Cristina Fernández de Kirchner]], à la présidence. Elle est réélue en 2011. Les [[élections générales argentines de 2015|élections générales de 2015]] voient la victoire de [[Mauricio Macri]], opposant au dauphin de la présidente sortante, qui ne pouvait se représenter après deux mandats. 

=== Mandat de [[Mauricio Macri]] ===

{{pertinence détail|En janvier 2016, la militante indigène et élue du [[Parlement sud-américain]] Milagro Salas est incarcérée, en dépit de son immunité parlementaire, pour avoir organisé une manifestation déclarée illégale par les autorités&lt;ref&gt;{{Article|langue=|auteur1=|prénom1=|nom1=|titre=¿Quién es Milagro Sala?|périodique=teleSUR|date=2016-12-15|issn=|lire en ligne=http://www.telesurtv.net/news/Quien-es-Milagro-Sala-20160116-0042.html|consulté le=|pages=}}&lt;/ref&gt;. Les [[Organisation des Nations unies|Nations Unies]] qualifient sa détention « d'illégale et d'arbitraire » et sollicitent sa libération, tout comme la [[Commission interaméricaine des droits de l'homme|Commission interaméricaine des droits de l’homme]] et différentes associations de défense des droits de l'homme&lt;ref&gt;{{Lien web|langue=|titre=Página/12 :: Ultimas Noticias :: La ONU reclamó al Gobierno la &quot;liberación inmediata&quot; de Milagro Sala|url=https://www.pagina12.com.ar/diario/ultimas/20-312918-2016-10-28.html|site=www.pagina12.com.ar|date=|consulté le=}}&lt;/ref&gt;}}.

{{pertinence détail|En aout 2017, un jeune homme disparait après avoir participé à une manifestation [[Mapuches|mapuche]] (Amérindiens vivant en Patagonie). Selon des témoins, il aurait été kidnappé et battu par la police, mais le gouvernement affirme ne pas avoir d’informations. Outre la disparition d'un manifestant, [[Amnesty International]] dénonce « les violations des droits humains » perpétrées par la gendarmerie en raison de la violence de l'intervention&lt;ref&gt;{{Article|langue=fr|auteur1=|prénom1=|nom1=|titre=Disparition en Argentine d’un jeune manifestant après une intervention policière|périodique=Le Monde.fr|date=2017-08-10|issn=|lire en ligne=http://www.lemonde.fr/ameriques/article/2017/08/10/disparition-en-argentine-d-un-jeune-manifestant-apres-une-intervention-policiere_5170931_3222.html|consulté le=2017-08-11|pages=}}&lt;/ref&gt;}}.

== Extrême droite ==

Depuis au moins les années 1930, il existe une [[extrême droite]] argentine organisée (création du Parti fasciste argentin en 1932, élection du gouverneur de Buenos Aires [[Manuel Fresco]] en 1935, [[Mouvement nationaliste Tacuara]] des années 1960 qui organisa une forte campagne antisémite après l'enlèvement du nazi [[Adolf Eichmann]] par le [[Mossad]]). Celle-ci, désignée sous le terme de « [[national-catholicisme]] », eut une influence importante dans l'armée et l'Église (avec notamment l'abbé [[Julio Meinvielle]] ; la [[Cité catholique]] fondée par [[Jean Ousset]], un disciple de [[Charles Maurras|Maurras]], proche par ailleurs de l'archévêque [[Antonio Caggiano]], ou le magazine ''[[Cabildo (revue)|Cabildo]]'') et les différents coups d'État (« [[Révolution libératrice]] », « [[Révolution argentine]] » de 1966 et [[coup d'Etat de mars 1976]], préparé, entre autres, par l'activisme violent de l'[[Alliance anticommuniste argentine]] et de la ''[[Concentración Nacional Universitaria]]''), celle-ci fut intégrée au régime de [[Jorge Rafael Videla]] après mars 1976, participant aux nombreux [[escadrons de la mort]], ce qui lui ôta toute existence indépendante du pouvoir.

Depuis la [[transition démocratique]] des années 1980, elle se montre plus discrète, à l'exception des soulèvements militaires organisés par les [[Carapintadas]]. Elle n'en continue pas moins d'exister, avec la fondation du {{Lien|langue=es|trad=Partido Nuevo Triunfo|fr=Partido Nuevo Triunfo|texte=Partido Nuevo Triunfo}} en 1990, par {{Lien|langue=es|trad=Alejandro Biondini|fr=Alejandro Biondini|texte=Alejandro Biondini}}, ou la re-création du magazine national-catholique et antisémite ''[[Cabildo (revue)|Cabildo]]''. La [[Cour suprême (Argentine)|Cour suprême]] a néanmoins ordonné la dissolution de ce parti en 2009 en raison de déclarations nazies et antisémites&lt;ref&gt;[http://ecodiario.eleconomista.es/internacional/noticias/1105848/03/09/Corte-Suprema-rechaza-personeria-politica-a-partido-neonazi-en-Argentina.html Corte Suprema rechaza personería política a partido neonazi en Argentina], ''[[El Economista (Espagne)|El Economista]]'', 17 mars 2009&lt;/ref&gt;.

Par ailleurs, {{Lien|langue=es|trad=Gustavo Breide Obeid|fr=Gustavo Breide Obeid|texte=Gustavo Breide Obeid}}, l'un des partisans du ''Carapintada'' Seineldín et participants à son putsch, condamné à 7 ans de prison, a fondé en 1996 le marginal ''{{Lien|langue=es|trad=Partido Popular por la Reconstrucción|fr=Partido Popular por la Reconstrucción|texte=Partido Popular por la Reconstrucción}}''. Candidat à l'élection présidentielle de 2003 et de 2007, il obtint à [[élections générales argentines de 2007|cette dernière]] {{formatnum:45113}} voix, soit 0,25 % des suffrages exprimés.

== Notes et références ==
{{Références}}

== Voir aussi ==

=== Bibliographie ===
* ''L'Argentine des Kirchner : dix ans après la crise'', Choiseul, Paris, 2011, 142 p. ({{numéro|82}} de la revue ''Problèmes d'Amérique Latine'', 2011)

=== Articles connexes ===
* [[Économie de l'Argentine]]
* [[Histoire de l'Argentine]]
* [[Liste des chefs d'État argentins]]
* [[Représentations diplomatiques de l'Argentine]]

=== Liens externes ===
{{Autres projets|Commons=Category:Politics of Argentina}}
* {{es}} [http://www.presidencia.gov.ar/ Site officiel du gouvernement]

{{Palette
| Politique en Argentine
| Politique en Amérique du Sud
}}
{{Portail|Argentine|politique}}

[[Catégorie:Politique en Argentine]]</text>
      <sha1>6ujeut0lssokw4wtdk0rupp05fbanb0</sha1>
    </revision>
  </page>
  </mediawiki>